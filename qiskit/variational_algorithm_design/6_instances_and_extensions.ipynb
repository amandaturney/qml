{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instances and Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are notes from each section of the qiskit course documentation found on this page: https://learn.qiskit.org/course/algorithm-design/instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Quantum Eigensolver (VQE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image vqe](./instances_VQE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VQE is one of the most widely used variational quantum algorithms. They layout is as follows:\n",
    "\n",
    "1. Prepare reference operators $U_R$ to go from $\\ket{0}$ to $\\ket{\\rho}$\n",
    "2. Apply variational form $U_V(\\vec{\\theta})$ to create an ansatz $U_A(\\vec{\\theta})$\n",
    "3. Bootstrap if we have a similar problem (typically found via classical simulation or sampling). Each optimizer will be bootstrapped differently, resulting in an initial set of parameter vectors\n",
    "4. Evaluate the cost function\n",
    "5. Use classical optimizer to select next set of parameters\n",
    "6. Repeat until process converges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subspace Search VQE (SSVQE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image ssvqe](./instances_SSVQE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSVQE is a variant of VQE that allows for obtaining the first k eigenvalues of an observable. SSQVE does this by adding weights to help prioritize optimizing the term with the largest weights and starting with an initial set of reference states that are all mutually orthogonal. The procedure is as follows:\n",
    "\n",
    "1. Prepare k different reference states by applying a unitary $U_R$ to the k different computational basis states.\n",
    "2. Apply the variational form to each reference state resulting in the ansatz.\n",
    "3. Bootstrapif a similar problem is available.\n",
    "4. Evaluate the cost function for all prepared states on a quantum computer. This involves calculating the expectation value of the observable for our state and multiplying the result by the associated weight for that reference state and then summing all weighted expecationa values for the cost function.\n",
    "5. Use classical optimizer to get next set of parameters\n",
    "6. Repeat until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Quantum Deflation (VQD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image vqd](./instances_VQD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VQD also obtains the first k eigenvalues of an observable but does so with the use of a penalty cost to guide the optimization process. The general idea is to obtain the lowest eigenvalue as usual but then to obtain the next eigenvalue, $\\lambda_1$, instead of minimizing the cost function, the following is optimized:\n",
    "\n",
    "$C_1(\\vec{\\theta}) := C_0(\\vec{\\theta}) + \\Beta_0|\\bra{\\psi(\\vec{\\theta})}\\ket{\\psi(\\vec{\\theta^0})}|^2$\n",
    "\n",
    "The additional term above is adding a penalty for the state not being orthogonal to the previously obtained state. The procedure is as follows:\n",
    "\n",
    "1. Prepare the reference operator $U_R$\n",
    "2. Apply the variational form\n",
    "3. Bootstrap if we have a similar problem\n",
    "4. Evaluate the cost function, which involves computing k excited states and an array of $\\Beta$'s defining the overlap penalty for each overlap term. This means calculate the expectation value for each k, calculate the penalty, and sum the two values for the cost function.\n",
    "5. Use a classical optimizer to chose the next set of parameters.\n",
    "6. Repeat until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Sampling Regression (QSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image qsr](./instances_QSR.png)\n",
    "\n",
    "One challenge of VQE is the multiple calls to a quantum computer required for each iterative step. The Quantum Sampling Regression helps solve this by completing a full optimization in a single call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind this is that the cost function can be expressed as a Fourier series. We can sample the cost function multiple times in order to obtain the Fourier coefficients for the 2S + 1 parameter values, we can recreate the Fa = c. Normalizing these values and using least-squares solution, these parameters of $\\vec{\\theta}$ can be found.\n",
    "\n",
    "1. Prepare reference operators $U_R$\n",
    "2. Apply variational form\n",
    "3. Bootstrap is we have a similar problem\n",
    "4. Sample the cost function at least T times\n",
    "5. Compute the Fourier coefficients of the samples (ie solve the normalized linear system of equations)\n",
    "6. Solve for the global minimum of the resulting regression function on a classical machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Question/Comment: </font> Want to come back to this to understand it more in depth. I am not sure how this method finds the global minimum with just a single initial theta?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
